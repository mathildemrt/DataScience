# Hive 

Hive is data warehouse built on top of Apache Hadoop. It is used to organize your data into tables on HDFS, and to executes SQL-like queries on them as Map Reduce jobs.

For this series of exercises we will use the Zeppelin notebook. This is yet anoter commonly used notebook, similar to Jupyter notebooks that you are already familiar with. We are using this notebook because it is installed by default with the Horthonworks HDP distribution.

Open a browser and log in the Zeppelin UI with your EPFL gaspar username and password at https://iccluster045.iccluster.epfl.ch:9995/ .

Once logged in, from your Zeppelin homepage, select the import note option, and copy the URL of this classâ€™s notebook .

You can now open the notebook in Zeppelin and start working on the exercises. As a bonus you can repeat the same exercises using the hive command in a terminal.

Data source in this exercise: The twitter stream grab provided thanks to the internet archive